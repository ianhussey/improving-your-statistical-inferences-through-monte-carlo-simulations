# Writing functions

Two of the key steps in a simulation study (generate data and analyze data) require us to know how to write functions. This chapter explains what functions are and how to write them.

## To add

- requirements / input checks? errors, warnings.
- [{parameters}](https://easystats.github.io/parameters/)
- documenting functions using roxygen?
- unit tests?

## What is a function?

A function is a piece of code that receives input(s), does something with it, and returns output(s). 

To take two very simple example, the `sum()` function calculates the sum of the number inputs passed to it:

```{r}

x <- -1
y <- -3

z <- sum(x, y)

z

```

When we run the code for a given function, we typically refer to this as 'calling' the function. The inputs we provide to functions are referred to as 'arguments'. Functions are called using its name, with its arguments being placed inside round brackets: `function_name(argument1, argument2, ... argumentN)`. 

To take a second example, the `abs()` function takes a numeric input and calculates their absolute value (i.e., removes the minus sign):

```{r}

abs(z)

```

While base-R contains nearly three thousand functions, they are by no means all the functions you might need while cleaning and analyzing your data. That's why we use `install.packages()` and `library()` to install and load other functions, including those in the tidyverse packages (e.g., `select()` and `mutate()`).

When writing simulation studies, we often need to need to define our own custom functions. 

Imagine that you often needed to first sum numbers and then find their absolute values. Maybe you get tired of having to write the following every time:

```{r}

x <- -1
y <- -3

z <- abs(sum(x, y))

```

There is a general rule in coding: *try not to repeat yourself*, because repeating long chunks of code and slightly changing the bits you need is a common source of making errors.

Instead, we could write a custom function for this specific purpose:

```{r}

# define function
sum_and_absolute <- function(x, y){
  result <- abs(sum(y, x))
  return(result)
}

# call function
sum_and_absolute(-2, -5)
sum_and_absolute(1, 4)
sum_and_absolute(-10, 2)

```

Being able to do this becomes very important when a) you need to do something many thousands of times, often with small variations b) the thing you are doing becomes more complicated. You will encounter both when writing simulation studies. 

## Basic structure of a function

Functions have three components. 

1. Inputs
2. Do stuff
3. Outputs

It is useful to bear these in mind when writing, debugging and using functions. Most of the errors people make in writing code for functions, or their approach to writing that code, come from confusing the elements or forgetting one. 


Function usually have name that is used to call the function and use it.\* This is done by declaring the function, just as you would a variable, using the assignment operator (`<-`) and `function()`, which is the function to define new functions. 

1. Inputs. Inside the `function()` call are the function's arguments. In this case, `x` and `y`. 
2. Do stuff. Between the curly brackets, `{ }`, code defines what the function does internally.
3. Outputs. The `return()` function is used to define what the function should return as output.\*\* 

```{r}

# inputs between ()
sum_and_absolute <- function(x, y){ 
  # do stuff, between {}
  result <- abs(sum(y, x))
  # outputs in res()
  return(result)
}

```

\* Anonymous functions do exist, but we don't need to know about them right now. 
\*\* Coders have arguments about whether 'explicit' `return()`s should be used or not. It is possible not to use `return()`, but when learning about functions and their conceptual components it is a very useful to be explicit about what is the output. We therefore recommend it in this context. 

## Writing functions 

The worst way to write a function is the way you read the code for it. Instead, write it from the inside out, starting with the 'do stuff' and using hard coded values.

Let's write the `sum_and_absolute()` function from scratch, in the way we recommend.

### Step 1: Write the 'do stuff'

```{r}

# get just the sum() working
temp <- sum(-1, -3) 
temp

# get just the abs() working
temp2 <- abs(-4) 
temp2

# get them both working together
result <- abs(sum(-1, -3))
result

```

### Step 2: Convert hard-coded values to variables

Declare variables with hard-coded values, and substitute the hard-coded values in the code for these variables. 

```{r}

# declare variables
x <- -1
y <- -3

# substitute the variables in and check it still works
# result <- abs(sum(-1, -3))
result <- abs(sum(x, y))
result

```

These variables will become the function's arguments.

### Step 3: Wrap it

Decide on a descriptive name for the function. Declare the function using its name, the `<-` assignment operator, and the `function()` function. Add curly brackets, `{ }`, for where the 'do stuff' code will go.

```{r}
#| eval: false
#| include: true
# NB code will not run

sum_and_absolute <- function(){ 
}
```

Copy the code into the 'do stuff' between the curly brackets.

```{r}
#| eval: false
#| include: true
# NB code will not run

sum_and_absolute <- function(){
  result <- abs(sum(x, y))
}
```

The function still has no inputs or outputs. Add any variables it uses into the inputs between the round brackets, `( )`. 

```{r}
sum_and_absolute <- function(x, y){
  result <- abs(sum(x, y))
}
```

At this point, the function will run and won't throw any errors, but it also doesn't do what we want it to. For example:

```{r}
sum_and_absolute(-4, -11)
```

Check your learning: Why doesn't it do what we want it to? How would we fix it?

::: {.callout-note collapse="true" title="Click to show answer"}
The function has no outputs defined. 

It calculates the absolute value of the sum and assigns it to the variable `results`, but it does not return this value to the user. This is due to a concept called 'variable scoping', which is a bit more complex and we won't cover here.

Suffice to say: you can fix this by telling the function to not only calculate this value, but also return it using `return()`.

```{r}
sum_and_absolute <- function(x, y){
  result <- abs(sum(x, y))
  return(result)
}
```
:::

Once fixed, you can now call the function and it works correctly. 
```{r}
sum_and_absolute(-4, -11)
```

### Why build functions this way?

Because of variable scoping. Variable scoping means that we are usually unable to see the value of variables defined inside a function from outside that function unless they are returned by the function. 

This is probably not what you're used to in R, which mostly uses 'global' variables. For example, you are used to being able to define `my_text <- "hello"` and then being able to see or use the `my_text` variable elsewhere in your R script. This is not actually the norm in coding; the scope of variables is often more limited, such as being able to access variables created within a function only inside that function. 

tl;dr: because you can't see everything that's happening inside functions, you can't debug and fix them. Instead, write the code as you normally do, and convert working code into a function.

### Automatic function extraction

Once you have code that uses variables, you can actually have RStudio do the 'wrap it' step for you.

In your local copy of this .qmd, highlight the code in the chunk below, click 'Code'>'Extract Function', name it 'sum_and_absolute', and click 'ok'. You can see gifs of this [here](https://www.appsilon.com/post/r-studio-shortcuts-and-tips-part-2).

```{r}

result <- abs(sum(x, y))
result

```

Buyer beware: This method isn't perfect, as it doesn't add `return()` around `result` or ensure that you have written code to create outputs. But it can save you time.

## Argument defaults

The way to write a function in R is simple. It takes the following format:

`function_name <- function(argument1, argument2, ... argumentN) { [function goes in here] }`

Let's look at a simple example. We'll create a new function called `sum2()`, which sums two numbers (using `sum()`, except it also rounds the output to two decimal places at the end. We'll also compare the outputs of `sum()` and `sum2()`:

```{r}

sum2 <- function(..., na.rm = FALSE, digits = 2) {
  
  round(sum(..., na.rm = na.rm), digits = digits)
  
}

sum(2.22222, 3.33333)
sum2(2.22222, 3.33333)

```

### Archetype

Note that this is pseudo-code only: chunk is set not to run (`eval=FALSE`).

```{r eval=FALSE}

# define function
function_name <- function(argument_1, # first argument is often the data, if the function takes a data frame as an argument
                          argument_2 = "default", # arguments can have defaults
                          argument_3) {
  # required packages
  require(dplyr)
  
  # checks
  # well written functions contain checks. 
  # e.g., if the function assumes that argument_1 is a data frame, check that this is the case.
  # note that it is more useful to write the function first and add checks later.
  if(!is.data.frame(argument_1)){
    stop("argument_1 must be a data frame")
  }
  
  # code that does things
  object_to_be_returned <- input_data_frame |>
    # do things
    mutate(value = value + 1)
  
  # object to be returned
  return(object_to_be_returned)
}

```

### Pseudocode

[needed]

### Built it, wrap it, run it

[needed]


-   Build the 'do stuff' part outside of a function first!
-   Wrap the 'do stuff' with input and output after you have 'do stuff' working. Why: so you don't have to fight variable scoping.




### Easy ways to mess up

built, wrap it, run it

-   The function must be present in your environment to be usable, and must be called to be used
-   Check that your function actually works as you expect, not just that it runs. Give it lots of different input values that should and should not work, and check you get the correct outputs.

### Applied example: The false positive rate of AI detection tools

Imagine a test has has a false positive rate of 5%, like the standard alpha value for a p-value. 

If you apply this test many times to independent cases without applying familywise error corrections, what is the resulting false positive rate?

Let's put this in meaningful terms. Many professors and universities now run essays and assignments through AI detection tools. But students submit many essays and assignments throughout their degree. What is the probability that, assuming you never violate the AI policy, one of your assignments is falsely flagged as using AI in a way that wasn't allowed? 

#### Math

The familywise error rate ($\alpha_{\text{total}}$) for independent tests is the probability of observing at least one false positive ($P(V \geq 1)$), which can be reexpressed as the probability of not observing true positives ($1 - P(V = 0)$). This is the product of the individual probabilities of false positives ($1 - \prod_{i=1}^{n} (1 - \alpha_i)$), which simplifies to:

$$
\begin{align}
\alpha_{\text{total}} &= P(V \geq 1) \\
&= 1 - P(V = 0) \\
&= 1 - \prod_{i=1}^{n} (1 - \alpha_i) \\
&= 1 - (1 - \alpha)^n
\end{align}
$$

Horrible, disgusting math which most of you want to avoid. But the code to do it is quite simple.

#### Hard coded

Assuming individual false positives of 5% and 10 total tests.

```{r}

1 - (1 - 0.05)^10

```

#### Extract variables

What about other values of alpha and n? We could make them variables at the top of the chunk that are easier to change.

```{r}

# variables
alpha <- 0.05
n <- 10

# code
1 - (1 - alpha)^n

```

#### Wrap it

Defining our own custom function involves putting the variables as arguments inside the `function()` call, and putting the code inside its `{}`.

We can then call the function using its name.

```{r}

# define function
calc_aggregate_fpr <- function(n, alpha = 0.05) {
  1 - (1 - alpha)^n
}

# usage
calc_aggregate_fpr(n = 10)

```

This also lets us call it an arbitrary number of times, eg for different values of n

```{r}

calc_aggregate_fpr(n =  5)
calc_aggregate_fpr(n = 10)
calc_aggregate_fpr(n = 15)
calc_aggregate_fpr(n = 20)
calc_aggregate_fpr(n = 25)

```

#### Use one of {purrr}'s `map()` functions to apply the custom function to many inputs - move to purrr chapter

This previews some skills we'll learn in a future chapter: calling a function multiple times within a tidy workflow by mapping it on to a set of input columns.

```{r}
#| include: false

library(tibble)
library(dplyr)
library(purrr)

experiment <- 
  # define many values of n as different rows in a data frame or tibble
  tibble(n = 1:20) 

# view 
experiment

results <- experiment |>  
  # use mutate to create a new column, fpr, by calling the custom function for each row, using n as the input
  # use a _dbl map function as the output is a numeric (double precision floating point) variable
  mutate(fpr = map_dbl(.x = n, 
                       .f = calc_aggregate_fpr))

results

```

Because we've done this in a tidy format in a tibble, we can easily plot the results too.

```{r}

library(ggplot2)

ggplot(results, aes(n, fpr)) +
  geom_line() +
  geom_point() +
  theme_linedraw()

```

What if we want to vary not only n but also alpha, and see all combinations of them? This previews some skills we'll learn in a later chapter: defining crossed experiment conditions using `expand_grid()`.

```{r}

library(tidyr)

# define many values of n and alpha, and then have them 'crossed' to create all permutations of them, using expand_grid()
experiment <- 
  expand_grid(n = 1:20,
              alpha = c(0.01, 0.05, 0.10)) 

# view the combinations used in the experiment
experiment

results <- experiment |>  
  # use mutate to create a new column, fpr, by calling the custom function for each row
  # use a map2_ function as there are two inputs, n and alpha
  # these are passed by location, .x to the first argument, .y to the second
  mutate(fpr = map2_dbl(.x = n, 
                        .y = alpha,
                        .f = calc_aggregate_fpr))

results

```

```{r}

results |>
  mutate(alpha = as.factor(alpha)) |>
  ggplot(aes(n, fpr, color = alpha, group = alpha)) +
  geom_line() +
  geom_point() +
  theme_linedraw() 

```



### Practice


#### Exercises

- math stuff
- convert ms to s
- convert n_months to n_years and round

- mean by group
- mean and sd and N by group
- differences in means between groups
- mean and sd and N and differences in means between groups

- rand between 0-9 - runif()
- two random numbers between 0-9, third column that is the larger number

- remove ms suffix "2000 ms" to 2000L 
- tidy_gender(): tolower, remove hypens (non-binary), case_when() for different m/male/man, etc
- tidy_age remove non numbers, convert to number, etc

- rnorm() 
- rnorm() + round()
- rnorm() + mean

- rbinom() as coin N flips in a row

- keeping it tidy
- two rnorm columns in a df, intervention and control
- two rnorm columns in a df, int and ctrl, then pivoting longer to have a condition and score column

### Content to move

#### Exercise 1 t test p value - analysis functions chapter

```{r}

# data to be analyzed using the analysis function
data_simulated_intervention <- 
  tibble(condition = "intervention", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- 
  tibble(condition = "control", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control)

```

```{r}

# define function
t_test_p_value <- function(data) {
  
  res <- t.test(formula = score ~ condition, 
                data = data)
  
  return(res$p.value)
}

# call function
t_test_p_value(data_simulated)

```

How would I build this from scratch? What's the first thing I would type?

```{r}




























```

#### Exercise 2 - analysis functions chapter

The purpose of a t-test is to test differences in means between groups. 

Weirdly, base-R's built in `t.test()` function does not actually return an estimate of this difference in means between groups, as [Uri Simonsohn recently pointed out](https://datacolada.org/132). 

Write a function that fits a t-test, returns results in tidy format, and includes an estimate of the difference in means between groups.

There are two ways to do this: 1) calculating the means from the data directly, 2) calculating the difference from the two estimated means returned by the `t.test()` function. Practice writing functions by implementing both.

```{r}



```

#### Exercise 3 - move somewhere

```{r}

library(forcats)
library(faux)

set.seed(42)

# data for t test
data_intervention <- 
  tibble(condition = "intervention", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_control <- 
  tibble(condition = "control", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_for_ttest <- 
  bind_rows(data_intervention,
            data_control) |>
  # control's factor levels must be ordered so that intervention is the first level and control is the second
  # this ensures that positive Cohen's d values refer to intervention > control and not the other way around.
  mutate(condition = fct_relevel(condition, "intervention", "control"))


# data for correlation
data_for_correlation <- rnorm_multi(n = 100, 
                                    vars = 2, 
                                    mu = 0, 
                                    sd = 1, 
                                    r = 0.5, 
                                    varnames = c("X", "Y"))

```

### Further reading

Although we have practiced writing custom functions to extract statistical results / model parameters, it is worth knowing that the {easystats} family of packages includes [{parameters}](https://easystats.github.io/parameters/) package, which does a very good job of extracting model parameters from a very wide range of models including base R functions, {lavaan}, {psych}, and other packages. If you want to extract values from a model, consider using {parameters} to do a lot of the work for you when writing your function.

Separately, the [{report}](https://easystats.github.io/report/) package will fully report the results of many common analyses for you. e.g.:

```{r}

library(report)

data_simulated_intervention <- 
  tibble(condition = "intervention", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated_control <- 
  tibble(condition = "control", 
         score = rnorm(n = 50, mean = 0, sd = 1))

data_simulated <- 
  bind_rows(data_simulated_intervention,
            data_simulated_control)

t.test(score ~ condition, data = data_simulated) |>
  report::report()

```






